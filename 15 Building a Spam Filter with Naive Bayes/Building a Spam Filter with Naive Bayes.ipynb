{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building a Spam Filter with Naive Bayes\n",
    "\n",
    "---\n",
    "\n",
    "## 1. Introduction\n",
    "\n",
    "In this project, we will **use the multinomial Naive Bayes algorithm to create a spam filter** using a [dataset of SMS messages](https://archive.ics.uci.edu/ml/datasets/sms+spam+collection). The program will:\n",
    "\n",
    "- Learn how humans classify messages.\n",
    "- Use that knowledge to estimate probabilities of whether a new message is spam or non-spam.\n",
    "- Classify a new message based on these probability values:\n",
    "    - If the probability for spam is greater, then it classifies the message as spam. \n",
    "    - Otherwise, it classifies it as non-spam.\n",
    "    - If the two probability values are equal, then we may need a human to classify the message.\n",
    "\n",
    "Our aim is to achieve an **accuracy of at least 80%** i.e. at least 80% of the new messages will be classified correctly as spam or non-spam.\n",
    "\n",
    "---\n",
    "\n",
    "## 2. Open and Explore the Data\n",
    "\n",
    "Let's start by reading the dataset of messages. \n",
    "\n",
    "**Note that due to the nature of spam messages, the data contains content that may be offensive to some users.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Csv file has tab separator, no header row\n",
    "sms_spam = pd.read_csv('SMSSpamCollection', sep = '\\t', header = None, names = ['Label', 'SMS'])\n",
    "\n",
    "# Number of rows and columns\n",
    "print(f'The dataset has {sms_spam.shape[0]} rows and {sms_spam.shape[1]} columns.')\n",
    "\n",
    "# Display first 5 rows\n",
    "sms_spam.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 5572 messages in the dataset, and each is labelled as `spam` or `ham` (i.e. non-spam) by human input.\n",
    "\n",
    "We can also find out the percentage of spam messages in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type:   Percentage (%)\n",
      "ham     86.593683\n",
      "spam    13.406317\n",
      "Name: Label, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print('Type:   Percentage (%)')\n",
    "print(sms_spam['Label'].value_counts(normalize = True) * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "About 87% of the messages in the dataset are non-spam, while the remaining 13% are spam.\n",
    "\n",
    "---\n",
    "\n",
    "## 3. Segregate Training and Test Data\n",
    "\n",
    "To facilitate testing of the spam filter, let's split the data into two categories:\n",
    "- a training set to train the program on how to classify messages and\n",
    "- a test set to verify the performance of the program in classifying new messages.\n",
    "\n",
    "We will use 80% of the messages for training and the remaining 20% for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 4458 messages in the training set.\n",
      "There are 1114 messages in the test set.\n",
      "\n",
      "\n",
      "Type:   Percentage (%) in Training Set\n",
      "ham     86.54105\n",
      "spam    13.45895\n",
      "Name: Label, dtype: float64\n",
      "\n",
      "\n",
      "Type:   Percentage (%) in Test Set\n",
      "ham     86.804309\n",
      "spam    13.195691\n",
      "Name: Label, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Randomize order of messages in dataset\n",
    "sms_random = sms_spam.sample(frac = 1, random_state = 1)\n",
    "\n",
    "# Split randomized dataset into training and test sets\n",
    "train_index = round(len(sms_random) * 0.8)\n",
    "sms_train = sms_random.iloc[:train_index].reset_index(drop = True)\n",
    "sms_test = sms_random.iloc[train_index:].reset_index(drop = True)\n",
    "\n",
    "# Verify size of training and test sets\n",
    "print(f'There are {len(sms_train)} messages in the training set.')\n",
    "print(f'There are {len(sms_test)} messages in the test set.')\n",
    "\n",
    "print('\\n')\n",
    "\n",
    "# Show percentage of spam and ham in both sets\n",
    "print('Type:   Percentage (%) in Training Set')\n",
    "print(sms_train['Label'].value_counts(normalize = True) * 100)\n",
    "\n",
    "print('\\n')\n",
    "\n",
    "print('Type:   Percentage (%) in Test Set')\n",
    "print(sms_test['Label'].value_counts(normalize = True) * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The proportions of spam and ham messages in the training and test sets are similar to that in the full dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "## 4. Clean and Transform the Data\n",
    "\n",
    "We will transform the training data into a format that is more convenient to train the algorithm, by replacing the `SMS` column with a series of new columns. \n",
    "\n",
    "Each new column will represent a unique word in lower case, with the value indicating the number of times the word occurs in each message. This means that we will consider `secret` and `SECRET` as the same word.\n",
    "\n",
    "We will clean the `SMS` column with the following steps:\n",
    "- remove all punctuation,\n",
    "- convert all words to lower case and\n",
    "- split the message into a list of words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>SMS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>[yep, by, the, pretty, sculpture]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>[yes, princess, are, you, going, to, make, me,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ham</td>\n",
       "      <td>[welp, apparently, he, retired]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>[havent]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>[i, forgot, 2, ask, ü, all, smth, there, s, a,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Label                                                SMS\n",
       "0   ham                  [yep, by, the, pretty, sculpture]\n",
       "1   ham  [yes, princess, are, you, going, to, make, me,...\n",
       "2   ham                    [welp, apparently, he, retired]\n",
       "3   ham                                           [havent]\n",
       "4   ham  [i, forgot, 2, ask, ü, all, smth, there, s, a,..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove all punctuation\n",
    "sms_train['SMS'] = sms_train['SMS'].str.replace('\\W', ' ')\n",
    "\n",
    "# Convert words to lower case\n",
    "sms_train['SMS'] = sms_train['SMS'].str.lower()\n",
    "\n",
    "# Split string at space character\n",
    "sms_train['SMS'] = sms_train['SMS'].str.split()\n",
    "\n",
    "# Verify first few rows\n",
    "sms_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will create a `vocabulary` list which contains all the unique words from the messages in the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 7783 unique words in the vocabulary.\n"
     ]
    }
   ],
   "source": [
    "# Initiate empty list\n",
    "vocabulary = []\n",
    "\n",
    "# Iterate over the SMS column\n",
    "for sms in sms_train['SMS']:\n",
    "\n",
    "    # Append each string into the list\n",
    "    for word in sms:\n",
    "        vocabulary.append(word)\n",
    "\n",
    "# Transform into a set to remove duplicates\n",
    "vocabulary = set(vocabulary)\n",
    "\n",
    "print(f'There are {len(vocabulary)} unique words in the vocabulary.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use the vocabulary to build a dictionary named `word_counts_per_sms` where:\n",
    "- each key corresponds to a unique word from the vocabulary and\n",
    "- each value is a list of the word counts in each message from the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>although</th>\n",
       "      <th>got</th>\n",
       "      <th>lovin</th>\n",
       "      <th>imposter</th>\n",
       "      <th>burn</th>\n",
       "      <th>bear</th>\n",
       "      <th>600</th>\n",
       "      <th>515</th>\n",
       "      <th>ahmad</th>\n",
       "      <th>janinexx</th>\n",
       "      <th>...</th>\n",
       "      <th>14tcr</th>\n",
       "      <th>03</th>\n",
       "      <th>emigrated</th>\n",
       "      <th>2morrowxxxx</th>\n",
       "      <th>downloaded</th>\n",
       "      <th>fakeye</th>\n",
       "      <th>eerie</th>\n",
       "      <th>pobox75ldns7</th>\n",
       "      <th>09061221061</th>\n",
       "      <th>str</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 7783 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   although  got  lovin  imposter  burn  bear  600  515  ahmad  janinexx  ...  \\\n",
       "0         0    0      0         0     0     0    0    0      0         0  ...   \n",
       "1         0    0      0         0     0     0    0    0      0         0  ...   \n",
       "2         0    0      0         0     0     0    0    0      0         0  ...   \n",
       "3         0    0      0         0     0     0    0    0      0         0  ...   \n",
       "4         0    0      0         0     0     0    0    0      0         0  ...   \n",
       "\n",
       "   14tcr  03  emigrated  2morrowxxxx  downloaded  fakeye  eerie  pobox75ldns7  \\\n",
       "0      0   0          0            0           0       0      0             0   \n",
       "1      0   0          0            0           0       0      0             0   \n",
       "2      0   0          0            0           0       0      0             0   \n",
       "3      0   0          0            0           0       0      0             0   \n",
       "4      0   0          0            0           0       0      0             0   \n",
       "\n",
       "   09061221061  str  \n",
       "0            0    0  \n",
       "1            0    0  \n",
       "2            0    0  \n",
       "3            0    0  \n",
       "4            0    0  \n",
       "\n",
       "[5 rows x 7783 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize dictionary of unique words with zero values\n",
    "word_counts_per_sms = {unique_word: [0] * len(sms_train['SMS']) \n",
    "                       for unique_word in vocabulary}\n",
    "\n",
    "# Compute counts for each word in each message\n",
    "for index, sms in enumerate(sms_train['SMS']):\n",
    "    for word in sms:\n",
    "        word_counts_per_sms[word][index] += 1\n",
    "\n",
    "# Convert dictionary to dataframe\n",
    "word_counts = pd.DataFrame(word_counts_per_sms)\n",
    "word_counts.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can concatenate this new dataframe with the original training data, to retain the `Label` and `SMS` columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>SMS</th>\n",
       "      <th>although</th>\n",
       "      <th>got</th>\n",
       "      <th>lovin</th>\n",
       "      <th>imposter</th>\n",
       "      <th>burn</th>\n",
       "      <th>bear</th>\n",
       "      <th>600</th>\n",
       "      <th>515</th>\n",
       "      <th>...</th>\n",
       "      <th>14tcr</th>\n",
       "      <th>03</th>\n",
       "      <th>emigrated</th>\n",
       "      <th>2morrowxxxx</th>\n",
       "      <th>downloaded</th>\n",
       "      <th>fakeye</th>\n",
       "      <th>eerie</th>\n",
       "      <th>pobox75ldns7</th>\n",
       "      <th>09061221061</th>\n",
       "      <th>str</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>[yep, by, the, pretty, sculpture]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>[yes, princess, are, you, going, to, make, me,...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ham</td>\n",
       "      <td>[welp, apparently, he, retired]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>[havent]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>[i, forgot, 2, ask, ü, all, smth, there, s, a,...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 7785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Label                                                SMS  although  got  \\\n",
       "0   ham                  [yep, by, the, pretty, sculpture]         0    0   \n",
       "1   ham  [yes, princess, are, you, going, to, make, me,...         0    0   \n",
       "2   ham                    [welp, apparently, he, retired]         0    0   \n",
       "3   ham                                           [havent]         0    0   \n",
       "4   ham  [i, forgot, 2, ask, ü, all, smth, there, s, a,...         0    0   \n",
       "\n",
       "   lovin  imposter  burn  bear  600  515  ...  14tcr  03  emigrated  \\\n",
       "0      0         0     0     0    0    0  ...      0   0          0   \n",
       "1      0         0     0     0    0    0  ...      0   0          0   \n",
       "2      0         0     0     0    0    0  ...      0   0          0   \n",
       "3      0         0     0     0    0    0  ...      0   0          0   \n",
       "4      0         0     0     0    0    0  ...      0   0          0   \n",
       "\n",
       "   2morrowxxxx  downloaded  fakeye  eerie  pobox75ldns7  09061221061  str  \n",
       "0            0           0       0      0             0            0    0  \n",
       "1            0           0       0      0             0            0    0  \n",
       "2            0           0       0      0             0            0    0  \n",
       "3            0           0       0      0             0            0    0  \n",
       "4            0           0       0      0             0            0    0  \n",
       "\n",
       "[5 rows x 7785 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Concatenate word_counts with training data\n",
    "sms_train_clean = pd.concat([sms_train, word_counts], axis = 1)\n",
    "sms_train_clean.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 5. Build the Spam Filter\n",
    "\n",
    "We will begin to create the spam filter with the cleaned training data, by defining the following constant terms:\n",
    "- `p_spam`: probability of a message being spam\n",
    "- `p_ham`: probability of a message being non-spam\n",
    "- `n_spam`: number of words in all the spam messages\n",
    "- `n_ham`: number of words in all the non-spam messages\n",
    "- `n_vocabulary`: number of words in the vocabulary\n",
    "- `alpha`: Laplace smoothing parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p_spam = 0.13459\n",
      "p_ham = 0.86541\n",
      "n_spam = 15190\n",
      "n_ham = 57237\n",
      "n_vocabulary = 7783\n",
      "alpha = 1\n"
     ]
    }
   ],
   "source": [
    "# Calculate probabilities\n",
    "[p_ham, p_spam] = sms_train_clean['Label'].value_counts(normalize = True)\n",
    "\n",
    "# Isolate spam and ham messages\n",
    "sms_train_spam = sms_train_clean[sms_train_clean['Label'] == 'spam']\n",
    "sms_train_ham = sms_train_clean[sms_train_clean['Label'] == 'ham']\n",
    "\n",
    "# Calculate number of words in messages\n",
    "n_spam = sum(sms_train_spam['SMS'].apply(len))\n",
    "n_ham = sum(sms_train_ham['SMS'].apply(len))\n",
    "\n",
    "# Define other variables\n",
    "n_vocabulary = len(vocabulary)\n",
    "alpha = 1\n",
    "\n",
    "# Display and verify all variables\n",
    "print(f'p_spam = {p_spam:.5f}')\n",
    "print(f'p_ham = {p_ham:.5f}')\n",
    "print(f'n_spam = {n_spam}')\n",
    "print(f'n_ham = {n_ham}')\n",
    "print(f'n_vocabulary = {n_vocabulary}')\n",
    "print(f'alpha = {alpha}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To implement the Naive Bayes algorithm, we also require a few other parameters:\n",
    "- P(word|Spam): the posterior probability that a spam message contains a certain word\n",
    "- P(word|Ham): the posterior probability that a non-spam message contains a certain word\n",
    "\n",
    "We will compute the values of these parameters for every word in the vocabulary, then store them in two dictionaries (`spam_parameters` and `ham_parameters`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample data from spam_parameters:\n",
      "[('although', 4.3529360553693465e-05), ('got', 0.00021764680276846734), ('lovin', 4.3529360553693465e-05), ('imposter', 4.3529360553693465e-05), ('burn', 4.3529360553693465e-05)]\n",
      "Sample data from ham_parameters:\n",
      "[('although', 4.6139649338665025e-05), ('got', 0.002660719778529683), ('lovin', 3.075976622577668e-05), ('imposter', 3.075976622577668e-05), ('burn', 3.075976622577668e-05)]\n"
     ]
    }
   ],
   "source": [
    "# Initiate dictionaries with zeros as parameters\n",
    "spam_parameters = {unique_word: 0 for unique_word in vocabulary}\n",
    "ham_parameters = {unique_word: 0 for unique_word in vocabulary}\n",
    "\n",
    "# Calculate posterior probabilities for each word in vocabulary\n",
    "for unique_word in vocabulary:\n",
    "    n_word_given_spam = sms_train_spam[unique_word].sum()\n",
    "    spam_parameters[unique_word] = (n_word_given_spam + alpha) / (n_spam + alpha * n_vocabulary)\n",
    "\n",
    "    n_word_given_ham = sms_train_ham[unique_word].sum()\n",
    "    ham_parameters[unique_word] = (n_word_given_ham + alpha) / (n_ham + alpha * n_vocabulary)\n",
    "    \n",
    "# Display sample values from each dictionary\n",
    "print('Sample data from spam_parameters:')\n",
    "print(list(spam_parameters.items())[:5])\n",
    "print('Sample data from ham_parameters:')\n",
    "print(list(ham_parameters.items())[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create the spam filter using the constants and parameters above. We will define the spam filter as a function that:\n",
    "- receives a new message as a string input,\n",
    "- calculates `P(Spam|message)` - posterior probability that the message is spam,\n",
    "- calculates `P(Ham|message)` - posterior probability that the message is non-spam and \n",
    "- classify the message as spam or non-spam.\n",
    "\n",
    "The new messages may contain words that are not part of the training vocabulary. Hence, we will ignore these new words in the probability computation.\n",
    "\n",
    "We will define the function below and verify its functionality on two messages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WINNER!! This is the secret code to unlock the money: C3421.\n",
      "P(Spam|message): 1.3481290211300841e-25\n",
      "P(Ham|message): 1.9368049028589875e-27\n",
      "Label: Spam\n",
      "\n",
      "\n",
      "Sounds good, Tom, then see u there\n",
      "P(Spam|message): 2.4372375665888117e-25\n",
      "P(Ham|message): 3.687530435009238e-21\n",
      "Label: Ham\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# Spam filter function with string input\n",
    "def classify(message):\n",
    "    \n",
    "    # Remove punctuation from string\n",
    "    message = re.sub('\\W', ' ', message)\n",
    "    # Convert string to lower case\n",
    "    message = message.lower()\n",
    "    # Split string into list of words\n",
    "    message = message.split()\n",
    "    \n",
    "    # Initialize p_spam_given_message and p_ham_given_message values\n",
    "    p_spam_given_message = p_spam\n",
    "    p_ham_given_message = p_ham\n",
    "    \n",
    "    # Iterate over each word in message\n",
    "    for word in message:\n",
    "        \n",
    "        # Update p_spam_given_message if the word is in spam_parameters\n",
    "        if word in spam_parameters:\n",
    "            p_spam_given_message *= spam_parameters[word]\n",
    "\n",
    "        # Update p_ham_given_message if the word is in ham_parameters \n",
    "        if word in ham_parameters:\n",
    "            p_ham_given_message *= ham_parameters[word]\n",
    "                \n",
    "    # Display probabilities of spam and ham\n",
    "    print('P(Spam|message):', p_spam_given_message)\n",
    "    print('P(Ham|message):', p_ham_given_message)\n",
    "    \n",
    "    # Classify message\n",
    "    if p_ham_given_message > p_spam_given_message:\n",
    "        print('Label: Ham')\n",
    "    elif p_ham_given_message < p_spam_given_message:\n",
    "        print('Label: Spam')\n",
    "    else:\n",
    "        print('Equal probabilities, have a human classify this!')\n",
    "        \n",
    "# Test message 1\n",
    "print('WINNER!! This is the secret code to unlock the money: C3421.')\n",
    "classify('WINNER!! This is the secret code to unlock the money: C3421.')\n",
    "\n",
    "print('\\n')\n",
    "\n",
    "# Test message 2\n",
    "print('Sounds good, Tom, then see u there')\n",
    "classify('Sounds good, Tom, then see u there')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 6. Test the Spam Filter\n",
    "\n",
    "Let's determine how well the spam filter performs on the test set. \n",
    "\n",
    "For every message in the test set, we will use the algorithm to generate a classification label and compare this against the actual label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>SMS</th>\n",
       "      <th>predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Later i guess. I needa do mcat study too.</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>But i haf enuff space got like 4 mb...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Had your mobile 10 mths? Update to latest Oran...</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>All sounds good. Fingers . Makes it difficult ...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>All done, all handed in. Don't know if mega sh...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Label                                                SMS predicted\n",
       "0   ham          Later i guess. I needa do mcat study too.       ham\n",
       "1   ham             But i haf enuff space got like 4 mb...       ham\n",
       "2  spam  Had your mobile 10 mths? Update to latest Oran...      spam\n",
       "3   ham  All sounds good. Fingers . Makes it difficult ...       ham\n",
       "4   ham  All done, all handed in. Don't know if mega sh...       ham"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# Spam filter function with string input\n",
    "def classify_test_set(message):\n",
    "    \n",
    "    # Remove punctuation from string\n",
    "    message = re.sub('\\W', ' ', message)\n",
    "    # Convert string to lower case\n",
    "    message = message.lower()\n",
    "    # Split string into list of words\n",
    "    message = message.split()\n",
    "    \n",
    "    # Initialize p_spam_given_message and p_ham_given_message values\n",
    "    p_spam_given_message = p_spam\n",
    "    p_ham_given_message = p_ham\n",
    "    \n",
    "    # Iterate over each word in message\n",
    "    for word in message:\n",
    "        \n",
    "        # Update p_spam_given_message if the word is in spam_parameters\n",
    "        if word in spam_parameters:\n",
    "            p_spam_given_message *= spam_parameters[word]\n",
    "\n",
    "        # Update p_ham_given_message if the word is in ham_parameters \n",
    "        if word in ham_parameters:\n",
    "            p_ham_given_message *= ham_parameters[word]\n",
    "                  \n",
    "    # Classify message      \n",
    "    if p_ham_given_message > p_spam_given_message:\n",
    "        return 'ham'\n",
    "    elif p_ham_given_message < p_spam_given_message:\n",
    "        return 'spam'\n",
    "    else:\n",
    "        return 'needs human classification'\n",
    "    \n",
    "# Compare actual and predicted labels\n",
    "sms_test['predicted'] = sms_test['SMS'].apply(classify_test_set)\n",
    "sms_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now calculate the spam filter accuracy as the percentage of test set messages that are correctly classified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1100 out of 1114 messages were classified correctly.\n",
      "The accuracy of the spam filter is 98.74%.\n"
     ]
    }
   ],
   "source": [
    "# Initialize variable for number of correct messages\n",
    "correct = 0\n",
    "\n",
    "# Total number of messages in the test set\n",
    "total = len(sms_test)\n",
    "\n",
    "for row in sms_test.iterrows():\n",
    "    row = row[1]\n",
    "    \n",
    "    # Messages classified correctly\n",
    "    if row['Label'] == row['predicted']:\n",
    "        correct += 1\n",
    "\n",
    "accuracy = correct / total * 100\n",
    "print(f'{correct} out of {total} messages were classified correctly.')\n",
    "print(f'The accuracy of the spam filter is {accuracy:.2f}%.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 7. Conclusion\n",
    "\n",
    "- Using the Naive Bayes algorithm, we built a spam filter for messages.\n",
    "- It achieved an accuracy of 98.74% on the test data, which exceeded the original target of 80%."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
